# Roesner-Michelle_IU14078032_DLMDWWDE02
Roesner-Michelle_IU14078032_DLMDWWDE02_P2
# Echtzeit-Datenpipeline mit Azure Databricks

## ğŸ” ProjektÃ¼bersicht

In diesem Projekt wurde eine cloudbasierte Streaming-Datenpipeline in Microsoft Azure Databricks umgesetzt. Ziel ist die Simulation, Aggregation und Auswertung von Sensordaten in Echtzeit â€“ inklusive Filterung, Klassifikation und Visualisierung.

## ğŸ¯ Zielsetzung

Die Anwendung bildet eine modulare Echtzeit-Architektur ab, um kontinuierlich erzeugte Temperaturdaten von simulierten Sensoren zu analysieren. Die Datenpipeline wurde in mehreren, klar abgegrenzten Schritten implementiert.

## âš™ï¸ Umgesetzte Verarbeitungsschritte

1. **Datengenerierung**  
   Erzeugung eines kontinuierlichen Datenstroms mit Zeitstempel, Sensor-ID und Temperaturwert.

2. **Aggregation**  
   Berechnung der durchschnittlichen Temperatur pro Sensor in 1-Minuten-Zeitfenstern.

3. **Filterung kritischer Werte**  
   Herausfiltern aller Temperaturwerte Ã¼ber 28 Â°C zur Anomalieerkennung.

4. **Klassifikation**  
   Einteilung der Messwerte in Statusklassen: â€niedrigâ€œ, â€normalâ€œ und â€kritischâ€œ.

5. **Visualisierung**  
   Tabellarische Auswertung (Anzahl, Durchschnitt, Maximaltemperatur je Status)  
   + Trendanalyse Ã¼ber TemperaturverlÃ¤ufe pro Sensor.

6. **Persistente Speicherung (nicht umgesetzt)**  
   Aufgrund fehlender Schreibrechte in der Azure-Umgebung konnte die Ausgabe in Parquet-Dateien nur konzeptionell vorbereitet werden.

## Tools & Technologien

- Databricks (Azure)
- PySpark / Structured Streaming
- SQL (Spark)
- In-Memory-Views
- GitHub fÃ¼r Versionierung

## Walkthrough-Video

â¡ï¸ [Hier klicken, um das Projektvideo anzusehen](#) *(Link bitte hier einfÃ¼gen)*

## Architekturdiagramm

Das konzeptionelle Architekturdiagramm befindet sich im Ordner `images/`.

---

## Ordnerstruktur
notebooks/ # Exportiertes Databricks-Notebook
images/ # PNG-Dateien (Architektur, Screenshots)
video/ # Walkthrough-Video oder Link
README.md # Dieses Dokument

## Hinweis

Die Umsetzung erfolgt im Rahmen des Moduls â€Data Engineeringâ€œ an der IU. Aufgrund von SystemeinschrÃ¤nkungen / fehlender Speicherzugriff in der Cloud-Umgebung wurden Teile der Architektur angepasst.
